{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edbcf2c",
   "metadata": {},
   "source": [
    "## Imports and Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075eb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Add parent directory to path to import models from root\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from models import InstructDeBERTa, BaselineModel\n",
    "from evaluate import evaluate_model\n",
    "\n",
    "# Ensure plots display inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab02848",
   "metadata": {},
   "source": [
    "## Load Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b634ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demo dataset from the local CSV\n",
    "data_path = 'demo_data.csv'\n",
    "print(f\"Loading data from {data_path}...\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Parse stringified lists into Python objects\n",
    "dataset = []\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        gt = ast.literal_eval(row['ground_truth'])\n",
    "        dataset.append({'text': row['text'], 'ground_truth': gt})\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row: {e}\")\n",
    "\n",
    "print(f\"Successfully loaded {len(dataset)} examples.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76efd31",
   "metadata": {},
   "source": [
    "## Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# Initialize Proposed Model (Beam Size = 1)\n",
    "print(\"Loading Instruct-DeBERTa (Beam=1)...\")\n",
    "model_v1 = InstructDeBERTa(device=device, beam_size=1)\n",
    "\n",
    "# Initialize Proposed Model with Hyperparameter Change (Beam Size = 3)\n",
    "print(\"Loading Instruct-DeBERTa (Beam=3)...\")\n",
    "model_v2 = InstructDeBERTa(device=device, beam_size=3)\n",
    "\n",
    "# Initialize Baseline\n",
    "print(\"Loading Baseline (DistilBERT)...\")\n",
    "model_base = BaselineModel(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18db51",
   "metadata": {},
   "source": [
    "## Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating Baseline...\")\n",
    "res_base = evaluate_model(model_base, dataset)\n",
    "\n",
    "print(\"Evaluating Instruct-DeBERTa (Beam=1)...\")\n",
    "res_v1 = evaluate_model(model_v1, dataset)\n",
    "\n",
    "print(\"Evaluating Instruct-DeBERTa (Beam=3)...\")\n",
    "res_v2 = evaluate_model(model_v2, dataset)\n",
    "\n",
    "# Compile Results\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'Baseline', **res_base},\n",
    "    {'Model': 'Instruct-DeBERTa (B=1)', **res_v1},\n",
    "    {'Model': 'Instruct-DeBERTa (B=3)', **res_v2}\n",
    "])\n",
    "\n",
    "results = results.replace({0.0: 0}) # Clean up for visualization\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43eb243",
   "metadata": {},
   "source": [
    "## Generate Graphical Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "metrics = ['ATE_F1', 'ASC_Accuracy', 'ASC_F1']\n",
    "models = results['Model'].tolist()\n",
    "\n",
    "x = range(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    vals = results.loc[i, metrics].values\n",
    "    offset = (i - len(models)/2) * width + width/2\n",
    "    rects = ax.bar([p + offset for p in x], vals, width, label=model, color=colors[i])\n",
    "    ax.bar_label(rects, padding=3, fmt='%.2f')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Performance on Laptop Domain (Demo Data)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim(0, 1.2)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493519fd",
   "metadata": {},
   "source": [
    "## Interactive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94893919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own sentence here!\n",
    "text = \"The processor speed is fantastic, but it overheats quickly.\"\n",
    "\n",
    "print(f\"Input: {text}\\n\")\n",
    "print(f\"Baseline Prediction: {model_base.predict_sentiment(text)}\")\n",
    "print(f\"Instruct-DeBERTa Prediction: {model_v1.predict(text)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
